# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/configuration-reference
version: 2.1
orbs:
 # Choose either one of the orbs below
    # welcome: circleci/welcome-orb@0.4.1
    aws-cli: circleci/aws-cli@2.0.3
# Define the jobs we want to run for this project
# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/configuration-reference/#jobs
commands:
      # Exercise - Rollback
      #destroy_environment:
        #steps:
          #- run:
              #name: Destroy environment
              # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
              # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
              #when: on_fail
              #command: |
                #aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID}
jobs:
  #say-hello:
    # Specify the execution environment. You can specify an image from Docker Hub or use one of our convenience images from CircleCI's Developer Hub.
    # See: https://circleci.com/docs/configuration-reference/#executor-job
    #docker:
      #- image: cimg/base:stable
    # Add steps to the job
    # See: https://circleci.com/docs/configuration-reference/#steps
    #steps:
      #- checkout
      #- run:
          #name: "Say hello"
          #command: "echo Hello, World!"
  #create_infrastructure: 
    #docker:
      #- image: amazon/aws-cli
    #steps:
      #- checkout
      #- run:
          #name: Create Cloudformation Stack
          #command: |
            #aws cloudformation deploy \
              #--template-file template.yml \
              #--stack-name myStack-${CIRCLE_WORKFLOW_ID} \
              #--region us-east-1
      # Fail the job intentionally to simulate an error.
      # Uncomment the line below if you want to fail the current step
      #- run: return 1
      #- destroy_environment

  #configure_infrastructure: 
    #docker:
      #- image: python:3.7-alpine3.11
    #steps:
      #- checkout
      #- add_ssh_keys:
          #fingerprints: ["df:de:50:19:54:fc:5f:5a:d9:1a:c7:b9:eb:c0:eb:4e"] # You can get this ID in the section where you registered the SSH Key
      #- run:
          #name: Install dependencies
          #command: |
            # install the dependencies needed for your playbook
            #apk add --update ansible 
      #- run:
          #name: Configure server
          #command: |
            #ansible-playbook -i inventory.txt main.yml
  #smoke_test:
    #docker:
      #- image: alpine:latest
    #steps:
      #- run: apk add --update curl
      #- run:
         # name: smoke test
          #command: |
           # URL="https://blog.udacity.com/"
            # Test if website exists
            #if curl -s --head ${URL} 
            #then
             # return 0
           # else
              #return 1
            #fi
  #smoke_test:
    #docker:
      #- image: alpine:latest
    #steps:
      #- run:
          #name: Test job
          # Fail the job intentionally to simulate an error.
          #command:  return 1
      #- destroy_environment  

  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
      # Uncomment the step below if you wish to upload all contents of the current directory to the S3 bucket
      - run: aws s3 sync . s3://mybucket-${CIRCLE_WORKFLOW_ID:0:7} --delete

  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt

  promote_to_production:
   docker:
     - image: amazon/aws-cli
   steps:
     - checkout
     - run:
         name: Execute cloudfront.yml
         command: |
           aws cloudformation deploy \
           --template-file cloudfront.yml \
           --stack-name productionTest \
           --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"
  
  clean_up_old_front_end:
   docker:
     - image: amazon/aws-cli
   steps:
     - checkout
     - run: yum install -y tar gzip
     - attach_workspace:
         at: ~/
     - run:
         name: Destroy the previous S3 bucket and CloudFormation stack. 
         # Use $OldBucketID environment variable or mybucket644752792305 below.
         # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
         command: |
           export OldBucketID=$(cat ~/textfile.txt)
           aws s3 rm "s3://${OldBucketID}" --recursive

# Orchestrate jobs using workflows
# See: https://circleci.com/docs/configuration-reference/#workflows
workflows:
  #say-hello-workflow:
    #jobs:
      #- say-hello
  my_workflow:
    jobs:
      #- create_infrastructure
       #- configure_infrastructure
      #- smoke_test
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
        - get_last_deployment_id
        - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
